{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "%matplotlib inline\n",
    "import os\n",
    "import os.path\n",
    "from netCDF4 import Dataset, num2date, date2num\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc \n",
    "import fnmatch\n",
    "from cycler import cycler\n",
    "import pandas as pd\n",
    "from pandas import read_csv, to_datetime, DataFrame\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import PathPatch\n",
    "from mpl_toolkits.basemap import Basemap # Basemap pour les cartes\n",
    "\n",
    "### TEM ponderation prof\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chemin des fichiers Ã  utiliser\n",
    "file_path = './ANNUAL_MEANS_BestAjustRivE_BoostW_BOUCLE/'\n",
    "full_list = os.listdir(file_path)\n",
    "full_list.sort()\n",
    "#full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dosa/MON_ENV_PYTHON/ARTICLE_IAV\n",
      "file exist: True\n",
      "Bathy : (160, 394) max : 5054.49 min : 20.5226\n"
     ]
    }
   ],
   "source": [
    "# LOADING GRID FILE AND VARIABLES\n",
    "!pwd\n",
    "grid_file = '../DATA/grille.nc' \n",
    "print 'file exist:', os.path.isfile(grid_file)\n",
    "\n",
    "f = Dataset(grid_file) # open netcdf\n",
    "# extracting variables\n",
    "lon_t = f.variables['longitude_t'][:] # extracting lon data\n",
    "lat_t = f.variables['latitude_t'][:] # extracting lat data\n",
    "#depth_t = f.variables['depth_t'][:]\n",
    "dz_t = f.variables['dz_t'][:]\n",
    "bathy = f.variables['h_w'][:]\n",
    "print 'Bathy :', np.shape(bathy), 'max :', np.max(bathy), 'min :', np.min(bathy)\n",
    "\n",
    "f.close()\n",
    "\n",
    "new_bath = np.ma.masked_where(bathy<200, bathy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970.nc\n",
      "Creating ncdf\n",
      "1971.nc\n",
      "Creating ncdf\n",
      "1972.nc\n",
      "Creating ncdf\n",
      "1973.nc\n",
      "Creating ncdf\n",
      "1974.nc\n",
      "Creating ncdf\n",
      "1975.nc\n",
      "Creating ncdf\n",
      "1976.nc\n",
      "Creating ncdf\n",
      "1977.nc\n",
      "Creating ncdf\n",
      "1978.nc\n",
      "Creating ncdf\n",
      "1979.nc\n",
      "Creating ncdf\n",
      "1980.nc\n",
      "Creating ncdf\n",
      "1981.nc\n",
      "Creating ncdf\n",
      "1982.nc\n",
      "Creating ncdf\n",
      "1983.nc\n",
      "Creating ncdf\n",
      "1984.nc\n",
      "Creating ncdf\n",
      "1985.nc\n",
      "Creating ncdf\n",
      "1986.nc\n",
      "Creating ncdf\n",
      "1987.nc\n",
      "Creating ncdf\n",
      "1988.nc\n",
      "Creating ncdf\n",
      "1989.nc\n",
      "Creating ncdf\n",
      "1990.nc\n",
      "Creating ncdf\n",
      "1991.nc\n",
      "Creating ncdf\n",
      "1992.nc\n",
      "Creating ncdf\n",
      "1993.nc\n",
      "Creating ncdf\n",
      "1994.nc\n",
      "Creating ncdf\n",
      "1995.nc\n",
      "Creating ncdf\n",
      "1996.nc\n",
      "Creating ncdf\n",
      "1997.nc\n",
      "Creating ncdf\n",
      "1998.nc\n",
      "Creating ncdf\n",
      "1999.nc\n",
      "Creating ncdf\n",
      "2000.nc\n",
      "Creating ncdf\n",
      "2001.nc\n",
      "Creating ncdf\n",
      "2002.nc\n",
      "Creating ncdf\n",
      "2003.nc\n",
      "Creating ncdf\n",
      "2004.nc\n",
      "Creating ncdf\n",
      "2005.nc\n",
      "Creating ncdf\n",
      "2006.nc\n",
      "Creating ncdf\n",
      "2007.nc\n",
      "Creating ncdf\n",
      "2008.nc\n",
      "Creating ncdf\n",
      "2009.nc\n",
      "Creating ncdf\n",
      "2010.nc\n",
      "Creating ncdf\n",
      "2011.nc\n",
      "Creating ncdf\n"
     ]
    }
   ],
   "source": [
    "# # NEW VERSION NUTRIENTS + ecriture ncdf\n",
    "\n",
    "# For 196 m\n",
    "count = 0\n",
    "time_s = np.zeros([len(full_list)]) # replace file_list here\n",
    "\n",
    "for file in full_list:\n",
    "    print file\n",
    "    \n",
    "    # extracting variables\n",
    "    f = Dataset(file_path+file) # open netcdf\n",
    "    chl_tot_196 = f.variables['chl_tot'][0,:,:,:] # extracting # [0,30:43,:,:]\n",
    "    f.close()\n",
    "    \n",
    "    # Creating empty arrays to store integrated values\n",
    "    vars()['chl_tot_196_'+str(file[0:4])] = np.zeros([160,394])\n",
    "    vars()['chl_tot_196_'+str(file[0:4])][:] = np.nan\n",
    "    \n",
    "    # At each lvl\n",
    "    for z in np.arange(31,43):\n",
    "        # taking this particular lvl, masking it to avoid useless computations\n",
    "        vars()['chl_tot_196_lvl_'+str(z)] = np.ma.masked_where(bathy<200, chl_tot_196[z,:,:])\n",
    "            \n",
    "    # for each (2D) point\n",
    "    for i in np.arange(0,160): # np.arange(0,160):\n",
    "        for j in np.arange(0,394):  #np.arange(0,394):\n",
    "            if np.ma.is_masked(new_bath[i,j]) == False: # to avoid useless points\n",
    "                #print 'i ,j =', i, j\n",
    "                chl_tot_ij = 0\n",
    "                chl_tot_this_lvl = 0\n",
    "\n",
    "                for z in np.arange(31,43): # there we need to consider one less lvl\n",
    "                    #print 'z =', z\n",
    "                    #print 'dz_t =', dz_t[z,i,j]\n",
    "                    #print 'chl_tot =', vars()['chl_tot_196_lvl_'+str(z)][i,j]\n",
    "                    chl_tot_this_lvl = vars()['chl_tot_196_lvl_'+str(z)][i,j] * dz_t[z,i,j]\n",
    "                    #print 'chl_tot_this_lvl =', chl_tot_this_lvl\n",
    "                    chl_tot_ij = np.nansum([chl_tot_ij, chl_tot_this_lvl])\n",
    "                    #print 'chl_tot_ij =', chl_tot_ij\n",
    "                    #print ' '\n",
    "                    \n",
    "                # Nuts => no need to weigh by depth                \n",
    "\n",
    "                # now putting our int chl value in the output array\n",
    "                vars()['chl_tot_196_'+str(file[0:4])][i,j] = chl_tot_ij\n",
    "                #print ' '\n",
    "                               \n",
    "    #print ' '\n",
    "    print 'Creating ncdf'\n",
    "    ### Creating NetCDF files for our outputs! ###\n",
    "    dates = []\n",
    "    \n",
    "    mask_alex = Dataset('./NC_INT_OUTPUTS_ALEX/ChlTot_Int150_'+str(file[0:4])+'.nc', 'w', format='NETCDF4_CLASSIC')\n",
    "    \n",
    "    # creating dimensions\n",
    "    time = mask_alex.createDimension('time',1)\n",
    "    ni_t = mask_alex.createDimension('nj_t', 160) \n",
    "    nj_t = mask_alex.createDimension('ni_t', 394)\n",
    "    \n",
    "    # creating variable with dimensions\n",
    "    #times = mask_alex.createVariable('time', np.int32, ('time',))  # float64\n",
    "    times = mask_alex.createVariable('time', np.float64, ('time',))  # float64\n",
    "    times.units = 'seconds since 1970-06-15 12:10:01' \n",
    "    times.calendar = 'gregorian'\n",
    "    \n",
    "    dates.append(datetime(int(file[0:4]), 10, 3, 12, 10, 1)) # according to ncdf files already existing \n",
    "    times[:] = date2num(dates, units = times.units, calendar = times.calendar)\n",
    "    #times[:] = date2num(dates)\n",
    "    #print dates\n",
    "\n",
    "    mask_t = mask_alex.createVariable('ChlTot_Int_0-151', np.float32, ('time', 'nj_t', 'ni_t'), fill_value=-9999) #'time', \n",
    "    mask_t.units = 'mmol.m-2'\n",
    "    #mask_t.units = 'degrees_Celsius'\n",
    "    \n",
    "    #print 'temp variable:', mask_alex.variables['Tem_Int_0-151']\n",
    "    \n",
    "    mask_t[:] =vars()['chl_tot_196_'+str(file[0:4])][:] # putting our df inside our variable\n",
    "    mask_alex.close() # writing the netcdf file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
