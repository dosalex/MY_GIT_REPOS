{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading libraries\n",
    "%matplotlib inline\n",
    "import os\n",
    "import os.path\n",
    "from netCDF4 import Dataset, num2date, date2num\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc \n",
    "import fnmatch\n",
    "from cycler import cycler\n",
    "import pandas as pd\n",
    "from pandas import read_csv, to_datetime, DataFrame\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.patches import PathPatch\n",
    "from mpl_toolkits.basemap import Basemap # Basemap pour les cartes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['moyenne_tem_1970.nc',\n",
       " 'moyenne_tem_1971.nc',\n",
       " 'moyenne_tem_1972.nc',\n",
       " 'moyenne_tem_1973.nc',\n",
       " 'moyenne_tem_1974.nc',\n",
       " 'moyenne_tem_1975.nc',\n",
       " 'moyenne_tem_1976.nc',\n",
       " 'moyenne_tem_1977.nc',\n",
       " 'moyenne_tem_1978.nc',\n",
       " 'moyenne_tem_1979.nc',\n",
       " 'moyenne_tem_1980.nc',\n",
       " 'moyenne_tem_1981.nc',\n",
       " 'moyenne_tem_1982.nc',\n",
       " 'moyenne_tem_1983.nc',\n",
       " 'moyenne_tem_1984.nc',\n",
       " 'moyenne_tem_1985.nc',\n",
       " 'moyenne_tem_1986.nc',\n",
       " 'moyenne_tem_1987.nc',\n",
       " 'moyenne_tem_1988.nc',\n",
       " 'moyenne_tem_1989.nc',\n",
       " 'moyenne_tem_1990.nc',\n",
       " 'moyenne_tem_1991.nc',\n",
       " 'moyenne_tem_1992.nc',\n",
       " 'moyenne_tem_1993.nc',\n",
       " 'moyenne_tem_1994.nc',\n",
       " 'moyenne_tem_1995.nc',\n",
       " 'moyenne_tem_1996.nc',\n",
       " 'moyenne_tem_1997.nc',\n",
       " 'moyenne_tem_1998.nc',\n",
       " 'moyenne_tem_1999.nc',\n",
       " 'moyenne_tem_2000.nc',\n",
       " 'moyenne_tem_2001.nc',\n",
       " 'moyenne_tem_2002.nc',\n",
       " 'moyenne_tem_2003.nc',\n",
       " 'moyenne_tem_2004.nc',\n",
       " 'moyenne_tem_2005.nc',\n",
       " 'moyenne_tem_2006.nc',\n",
       " 'moyenne_tem_2007.nc',\n",
       " 'moyenne_tem_2008.nc',\n",
       " 'moyenne_tem_2009.nc',\n",
       " 'moyenne_tem_2010.nc',\n",
       " 'moyenne_tem_2011.nc']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chemin des fichiers à utiliser\n",
    "file_path = './ANNUAL_MEANS_BestAjustRivE_BoostW_BOUCLE_NEW/TEM/'\n",
    "full_list = os.listdir(file_path)\n",
    "full_list.sort()\n",
    "full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dosa/MON_ENV_PYTHON/LAST_VALID\n",
      "file exist: True\n",
      "Bathy : (160, 394) max : 5054.49 min : 20.5226\n"
     ]
    }
   ],
   "source": [
    "# LOADING GRID FILE AND VARIABLES\n",
    "!pwd\n",
    "grid_file = '../DATA/grille.nc' \n",
    "print 'file exist:', os.path.isfile(grid_file)\n",
    "\n",
    "f = Dataset(grid_file) # open netcdf\n",
    "# extracting variables\n",
    "lon_t = f.variables['longitude_t'][:] # extracting lon data\n",
    "lat_t = f.variables['latitude_t'][:] # extracting lat data\n",
    "#depth_t = f.variables['depth_t'][:]\n",
    "dz_t = f.variables['dz_t'][:]\n",
    "bathy = f.variables['h_w'][:]\n",
    "print 'Bathy :', np.shape(bathy), 'max :', np.max(bathy), 'min :', np.min(bathy)\n",
    "\n",
    "f.close()\n",
    "\n",
    "new_bath = np.ma.masked_where(bathy<200, bathy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970.nc\n",
      "Creating ncdf\n",
      "1971.nc\n",
      "Creating ncdf\n",
      "1972.nc\n",
      "Creating ncdf\n",
      "1973.nc\n",
      "Creating ncdf\n",
      "1974.nc\n",
      "Creating ncdf\n",
      "1975.nc\n",
      "Creating ncdf\n",
      "1976.nc\n",
      "Creating ncdf\n",
      "1977.nc\n",
      "Creating ncdf\n",
      "1978.nc\n",
      "Creating ncdf\n",
      "1979.nc\n",
      "Creating ncdf\n",
      "1980.nc\n",
      "Creating ncdf\n",
      "1981.nc\n",
      "Creating ncdf\n",
      "1982.nc\n",
      "Creating ncdf\n",
      "1983.nc\n",
      "Creating ncdf\n",
      "1984.nc\n",
      "Creating ncdf\n",
      "1985.nc\n",
      "Creating ncdf\n",
      "1986.nc\n",
      "Creating ncdf\n",
      "1987.nc\n",
      "Creating ncdf\n",
      "1988.nc\n",
      "Creating ncdf\n",
      "1989.nc\n",
      "Creating ncdf\n",
      "1990.nc\n",
      "Creating ncdf\n",
      "1991.nc\n",
      "Creating ncdf\n",
      "1992.nc\n",
      "Creating ncdf\n",
      "1993.nc\n",
      "Creating ncdf\n",
      "1994.nc\n",
      "Creating ncdf\n",
      "1995.nc\n",
      "Creating ncdf\n",
      "1996.nc\n",
      "Creating ncdf\n",
      "1997.nc\n",
      "Creating ncdf\n",
      "1998.nc\n",
      "Creating ncdf\n",
      "1999.nc\n",
      "Creating ncdf\n",
      "2000.nc\n",
      "Creating ncdf\n",
      "2001.nc\n",
      "Creating ncdf\n",
      "2002.nc\n",
      "Creating ncdf\n",
      "2003.nc\n",
      "Creating ncdf\n",
      "2004.nc\n",
      "Creating ncdf\n",
      "2005.nc\n",
      "Creating ncdf\n",
      "2006.nc\n",
      "Creating ncdf\n",
      "2007.nc\n",
      "Creating ncdf\n",
      "2008.nc\n",
      "Creating ncdf\n",
      "2009.nc\n",
      "Creating ncdf\n",
      "2010.nc\n",
      "Creating ncdf\n",
      "2011.nc\n",
      "Creating ncdf\n"
     ]
    }
   ],
   "source": [
    "# NEW VERSION\n",
    "\n",
    "# For 196 m\n",
    "count = 0\n",
    "time_s = np.zeros([len(full_list)]) # replace file_list here\n",
    "\n",
    "for file in full_list:\n",
    "    print file\n",
    "    \n",
    "    # extracting variables\n",
    "    f = Dataset(file_path+file) # open netcdf\n",
    "    chl_tot_196 = f.variables['phosphate'][0,:,:,:] # extracting # [0,30:43,:,:]\n",
    "    f.close()\n",
    "    \n",
    "    # Creating empty arrays to store integrated values\n",
    "    vars()['chl_tot_196_'+str(file[0:4])] = np.zeros([160,394])\n",
    "    \n",
    "    # At each lvl\n",
    "    for z in np.arange(29,43): # 200m\n",
    "    #for z in np.arange(31,43): # 150m\n",
    "        # taking this particular lvl, masking it to avoid useless computations\n",
    "        vars()['chl_tot_196_lvl_'+str(z)] = np.ma.masked_where(bathy<200, chl_tot_196[z,:,:])\n",
    "            \n",
    "    # for each (2D) point\n",
    "    for i in np.arange(0,160):\n",
    "        for j in np.arange(0,394):\n",
    "            if np.ma.is_masked(new_bath[i,j]) == False: # to avoid useless points\n",
    "                chl_tot_ij = 0\n",
    "                chl_tot_this_lvl = 0\n",
    "\n",
    "                for z in np.arange(29,43): # there we need to consider one less lvl\n",
    "                    chl_tot_this_lvl = vars()['chl_tot_196_lvl_'+str(z)][i,j] * dz_t[z,i,j]\n",
    "                    chl_tot_ij = np.nansum([chl_tot_ij, chl_tot_this_lvl])\n",
    "\n",
    "                # now putting our int chl value in the output array\n",
    "                vars()['chl_tot_196_'+str(file[0:4])][i,j] = chl_tot_ij\n",
    "                \n",
    "    print 'Creating ncdf'\n",
    "    ### Creating NetCDF files for our outputs! ###\n",
    "    mask_alex = Dataset('./NC_INT_OUTPUTS_ALEX/Pho_Int200_'+str(file[0:4])+'.nc', 'w', format='NETCDF4_CLASSIC')\n",
    "    # creating dimensions\n",
    "    \n",
    "    # A REMODIFIER TOUT ÇA !!!\n",
    "    ni_t = mask_alex.createDimension('ni_t', 160) \n",
    "    # A REMODIFIER TOUT ÇA !!!\n",
    "    nj_t = mask_alex.createDimension('nj_t', 394) \n",
    "    # creating variable with dimensions\n",
    "    mask_t = mask_alex.createVariable('Pho_Int_0-212', np.int32, ('ni_t', 'nj_t')) # A REMODIFIER TOUT ÇA !!!\n",
    "    mask_t[:] =vars()['chl_tot_196_'+str(file[0:4])][:] # putting our df inside our variable\n",
    "    mask_alex.close() # writing the netcdf file!\n",
    "                               \n",
    "    #print ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moyenne_tem_1970.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1971.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1972.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1973.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1974.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1975.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1976.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1977.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1978.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1979.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1980.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1981.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1982.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1983.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1984.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1985.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1986.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1987.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1988.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1989.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1990.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1991.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1992.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1993.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1994.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1995.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1996.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1997.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1998.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_1999.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2000.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2001.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2002.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2003.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2004.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2005.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2006.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2007.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2008.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2009.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2010.nc\n",
      "Creating ncdf\n",
      "moyenne_tem_2011.nc\n",
      "Creating ncdf\n"
     ]
    }
   ],
   "source": [
    "# NEW TENTATIVE TEM pond + ecriture ncdf\n",
    "\n",
    "# For 196 m\n",
    "count = 0\n",
    "time_s = np.zeros([len(full_list)]) # replace file_list here\n",
    "\n",
    "for file in full_list:\n",
    "    print file\n",
    "    \n",
    "    # extracting variables\n",
    "    f = Dataset(file_path+file) # open netcdf\n",
    "    chl_tot_196 = f.variables['tem'][0,:,:,:] # extracting # [0,30:43,:,:]\n",
    "    f.close()\n",
    "    \n",
    "    # Creating empty arrays to store integrated values\n",
    "    vars()['chl_tot_196_'+str(file[12:16])] = np.zeros([160,394])\n",
    "    vars()['chl_tot_196_'+str(file[12:16])][:] = np.nan\n",
    "    \n",
    "    # At each lvl\n",
    "    for z in np.arange(31,43):\n",
    "        # taking this particular lvl, masking it to avoid useless computations\n",
    "        vars()['chl_tot_196_lvl_'+str(z)] = np.ma.masked_where(bathy<200, chl_tot_196[z,:,:])\n",
    "            \n",
    "    # for each (2D) point\n",
    "    for i in np.arange(0,160):\n",
    "        for j in np.arange(0,394):\n",
    "            if np.ma.is_masked(new_bath[i,j]) == False: # to avoid useless points\n",
    "                chl_tot_ij = 0\n",
    "                chl_tot_this_lvl = 0\n",
    "\n",
    "                #for z in np.arange(29,43): # 200m\n",
    "                for z in np.arange(31,43): # 150m\n",
    "                    chl_tot_this_lvl = vars()['chl_tot_196_lvl_'+str(z)][i,j] * dz_t[z,i,j]\n",
    "                    chl_tot_ij = np.nansum([chl_tot_ij, chl_tot_this_lvl])\n",
    "                    \n",
    "                # TEM => weighing by depth\n",
    "                chl_tot_ij = chl_tot_ij/150.96777 # for 151m case\n",
    "                # 211.94522 # for 212m case\n",
    "\n",
    "                # now putting our int chl value in the output array\n",
    "                vars()['chl_tot_196_'+str(file[12:16])][i,j] = chl_tot_ij\n",
    "                \n",
    "    print 'Creating ncdf'\n",
    "    ### Creating NetCDF files for our outputs! ###\n",
    "    dates = []\n",
    "    \n",
    "    mask_alex = Dataset('./NC_INT_OUTPUTS_ALEX/Tem_Int150_'+str(file[12:16])+'.nc', 'w', format='NETCDF4_CLASSIC')\n",
    "    # creating dimensions\n",
    "    time = mask_alex.createDimension('time',1)\n",
    "    #ni_t = mask_alex.createDimension('ni_t', 160) # save 11.04\n",
    "    #nj_t = mask_alex.createDimension('nj_t', 394) # save 11.04\n",
    "    ni_t = mask_alex.createDimension('nj_t', 160) \n",
    "    nj_t = mask_alex.createDimension('ni_t', 394)\n",
    "    \n",
    "    # creating variable with dimensions\n",
    "    times = mask_alex.createVariable('time', np.float64, ('time',))  # float64\n",
    "    times.units = 'seconds since 1970-06-15 12:10:01' \n",
    "    times.calendar = 'gregorian'\n",
    "    \n",
    "    dates.append(datetime(int(file[12:16]), 10, 3, 12, 10, 1)) # according to ncdf files already existing \n",
    "    times[:] = date2num(dates, units = times.units, calendar = times.calendar)\n",
    "    #times[:] = date2num(dates)\n",
    "    #print dates\n",
    "\n",
    "    #mask_t = mask_alex.createVariable('Tem_Int_0-151', np.float32, ('time', 'ni_t', 'nj_t'), fill_value=-9999) # save 11.04\n",
    "    mask_t = mask_alex.createVariable('Tem_Int_0-151', np.float32, ('time', 'nj_t', 'ni_t'), fill_value=-9999) # 11.04\n",
    "    #mask_t.units = 'mmol.m-2'\n",
    "    mask_t.units = 'degrees_Celsius'\n",
    "    \n",
    "    #print 'temp variable:', mask_alex.variables['Tem_Int_0-151']\n",
    "    \n",
    "    mask_t[:] =vars()['chl_tot_196_'+str(file[12:16])][:] # putting our df inside our variable\n",
    "    \n",
    "    mask_alex.close() # writing the netcdf file!\n",
    "                               \n",
    "    #print ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
